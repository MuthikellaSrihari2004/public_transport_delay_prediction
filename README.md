# HyderTrax - Hyderabad Public Transport Delay Prediction System

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Flask](https://img.shields.io/badge/flask-2.0+-green.svg)](https://flask.palletsprojects.com/)
[![XGBoost](https://img.shields.io/badge/xgboost-latest-orange.svg)](https://xgboost.readthedocs.io/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

> **An intelligent ML-powered web application for predicting public transport delays in Hyderabad**

## ğŸ¯ Overview

HyderTrax is a comprehensive data-driven machine learning solution that predicts transit delay durations for buses, metro, and trains in Hyderabad. The system integrates historical transport data, real-time weather information, traffic patterns, and event schedules to provide accurate delay predictions.

### Key Features

- âœ… **Real-time Delay Predictions** - Get instant predictions for any route
- âœ… **Multi-modal Transport** - Supports Bus, Metro, and Train services
- âœ… **Live Tracking** - Track services with stop-by-stop ETA updates
- âœ… **Weather Integration** - Real-time weather data from OpenWeather API
- âœ… **Historical Analysis** - Comprehensive EDA and visualization reports
- âœ… **RESTful API** - JSON API for third-party integrations
- âœ… **Modern Web UI** - Responsive, user-friendly interface

---

## ğŸ“‚ Project Structure

```
project/
â”œâ”€â”€ config.py                    # Centralized configuration
â”œâ”€â”€ main.py                      # Main pipeline orchestrator
â”œâ”€â”€ app.py                       # Flask web application
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ data/                    # Data pipeline
â”‚   â”‚   â”œâ”€â”€ make_dataset.py     # Synthetic data generation
â”‚   â”‚   â”œâ”€â”€ clean_data.py       # Data cleaning pipeline
â”‚   â”‚   â””â”€â”€ build_features.py   # Feature engineering
â”‚   â”‚
â”‚   â”œâ”€â”€ database/                # Database layer
â”‚   â”‚   â”œâ”€â”€ db_config.py        # Schema & initialization
â”‚   â”‚   â”œâ”€â”€ queries.py          # Query utilities
â”‚   â”‚   â””â”€â”€ migrate_data.py     # CSV to DB migration
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                  # ML models
â”‚   â”‚   â”œâ”€â”€ engine.py           # Prediction engine
â”‚   â”‚   â”œâ”€â”€ train_model.py      # Model training
â”‚   â”‚   â”œâ”€â”€ evaluate_model.py   # Model evaluation
â”‚   â”‚   â””â”€â”€ predict_terminal.py # CLI predictions
â”‚   â”‚
â”‚   â””â”€â”€ visualization/           # Data visualization
â”‚       â””â”€â”€ eda.py              # Exploratory data analysis
â”‚
â”œâ”€â”€ data/                        # Data storage
â”‚   â”œâ”€â”€ raw/                    # Raw generated data
â”‚   â”œâ”€â”€ processed/              # Cleaned & engineered data
â”‚   â””â”€â”€ transport.db           # SQLite database
â”‚
â”œâ”€â”€ models/                      # Trained ML models
â”‚   â”œâ”€â”€ xgboost_delay_model.pkl
â”‚   â””â”€â”€ label_encoders.pkl
â”‚
â”œâ”€â”€ templates/                   # HTML templates
â”‚   â”œâ”€â”€ base.html
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ prediction.html
â”‚   â””â”€â”€ schedule.html
â”‚
â”œâ”€â”€ static/                      # Static assets
â”‚   â””â”€â”€ css/
â”‚       â””â”€â”€ style.css
â”‚
â””â”€â”€ reports/                     # Generated reports
    â”œâ”€â”€ figures/                # EDA visualizations
    â””â”€â”€ eda_insights.md        # Analysis report
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- pip package manager
- (Optional) OpenWeather API key for real-time weather

### Installation

1. **Clone the repository** (or navigate to project directory)
   ```bash
   cd c:\Users\msrih\Documents\project
   ```

2. **Create a virtual environment**
   ```bash
   python -m venv venv
   ```

3. **Activate the virtual environment**
   - Windows:
     ```bash
     venv\Scripts\activate
     ```
   - Linux/Mac:
     ```bash
     source venv/bin/activate
     ```

4. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

5. **Configure environment**
   - The `.env` file already exists with default values
   - (Optional) Add your OpenWeather API key:
     ```bash
     # Edit .env file
     OPENWEATHER_API_KEY=your_actual_api_key_here
     ```

6. **Run the complete pipeline**
   ```bash
   python main.py
   ```
   This will:
   - Generate synthetic transport data
   - Clean and process the data
   - Engineer features
   - Train the ML model
   - Initialize the database
   - Migrate data to database

7. **Start the web application**
   ```bash
   python app.py
   ```

8. **Open your browser**
   Navigate to: http://localhost:8000

---

## ğŸ“– Usage

### Running the Complete Pipeline

```bash
# Run entire pipeline
python main.py

# Force regenerate all data and models
python main.py --force

# Skip specific steps
python main.py --skip-data          # Skip data generation
python main.py --skip-training      # Skip model training

# Run only database operations
python main.py --only-database
```

### Starting the Web Application

```bash
python app.py
```

The application will start on `http://localhost:8000`

### Using the CLI Prediction Tool

```bash
python src/models/predict_terminal.py
```

---

## ğŸŒ Web Interface

### Pages

1. **Homepage (`/`)**
   - Search form for route-based predictions
   - Displays all available services with delay predictions
   - Shows real-time weather and environmental context

2. **Prediction Page (`/predict`)**
   - Interactive prediction form
   - JSON API-powered results
   - Detailed delay insights

3. **Tracking Page (`/track/<service_id>`)**
   - Live service tracking
   - Stop-by-stop timeline
   - Real-time ETA updates

---

## ğŸ”Œ API Endpoints

### 1. Search Services (Form-based)

**Endpoint:** `POST /search`  
**Content-Type:** `application/x-www-form-urlencoded`

**Request:**
```
from_location=Secunderabad
to_location=Hitech City
travel_date=2026-01-26
transport_type=Bus
```

**Response:** HTML page with results

---

### 2. Search Services (JSON API)

**Endpoint:** `POST /api/search`  
**Content-Type:** `application/json`

**Request:**
```json
{
  "from": "Secunderabad",
  "to": "Hitech City",
  "date": "2026-01-26",
  "type": "Metro"
}
```

**Response:**
```json
{
  "schedules": [
    {
      "Service_ID": "METRO_001",
      "Scheduled_Departure": "09:00",
      "id": 1
    }
  ],
  "representative_insight": {
    "predicted_delay": 12,
    "delay_category": "Minor Delay",
    "confidence_score": 0.85,
    "primary_reason": "Heavy traffic conditions"
  }
}
```

---

### 3. Track Service (JSON API)

**Endpoint:** `GET /api/track/<service_id>?date=2026-01-26`

**Response:**
```json
{
  "service": { ... },
  "info": {
    "Service_ID": "BUS_042",
    "Start_Time": "09:02",
    "Reach_Time": "10:25"
  },
  "insights": {
    "predicted_delay": 15,
    "delay_category": "Minor Delay",
    "primary_reason": "Peak hour traffic"
  },
  "stops": [
    {
      "name": "Secunderabad",
      "est": "09:02",
      "sched": "09:00",
      "status": "Departed",
      "is_current": false
    }
  ]
}
```

---

## ğŸ§  Machine Learning Model

### Model Architecture

- **Algorithm:** XGBoost Regressor
- **Target Variable:** Delay (in minutes)
- **Features:** 15+ features including transport type, route, weather, traffic, temporal patterns

### Features Used

**Categorical:**
- Transport Type (Bus, Metro, Train)
- From/To Locations
- Weather Condition
- Traffic Density

**Numerical:**
- Temperature (Â°C)
- Humidity (%)
- Passenger Load
- Distance (km)
- Hour of Day
- Day of Week

**Engineered:**
- Weather-Traffic Interaction Index
- Is Weekend
- Is Peak Hour

### Performance Metrics

See `reports/` directory after running evaluation.

---

## ğŸ—„ï¸ Database Schema

### Tables

#### `schedules`
Stores all transport schedules with contextual information

```sql
CREATE TABLE schedules (
    id INTEGER PRIMARY KEY,
    date TEXT,
    transport_type TEXT,
    from_location TEXT,
    to_location TEXT,
    scheduled_departure TEXT,
    delay_minutes INTEGER,
    weather TEXT,
    temperature_c REAL,
    is_holiday INTEGER,
    is_peak_hour INTEGER,
    traffic_density TEXT,
    -- ... and more
);
```

#### `predictions`
Audit log of all predictions made

```sql
CREATE TABLE predictions (
    pred_id INTEGER PRIMARY KEY,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    from_location TEXT,
    to_location TEXT,
    predicted_delay INTEGER,
    reason TEXT
);
```

---

## ğŸ› ï¸ Configuration

All configuration is centralized in `config.py`:

- **Paths:** Data directories, model paths, database location
- **API Keys:** OpenWeather, Traffic APIs
- **Model Parameters:** Training hyperparameters
- **Flask Settings:** Debug mode, port, host

---

## ğŸ”§ Development

### Running Tests

```bash
# Create tests directory if it doesn't exist
mkdir tests

# Run tests (when available)
pytest tests/
```

### Viewing Logs

Logs are stored in `logs/hydertrax.log`

---

## ğŸ“Š Data Pipeline

```
1. Data Generation (make_dataset.py)
   â†“
2. Data Cleaning (clean_data.py)
   â†“
3. Feature Engineering (build_features.py)
   â†“
4. Model Training (train_model.py)
   â†“
5. Model Evaluation (evaluate_model.py)
   â†“
6. Database Setup (db_config.py)
   â†“
7. Data Migration (migrate_data.py)
   â†“
8. Web Application (app.py)
```

---

## ğŸ› Troubleshooting

### Issue: ModuleNotFoundError

**Solution:** Ensure you're in the project root and virtual environment is activated
```bash
cd c:\Users\msrih\Documents\project
venv\Scripts\activate
python -m pip install -r requirements.txt
```

### Issue: Database not found

**Solution:** Run the pipeline to initialize
```bash
python main.py --only-database
```

### Issue: Model file not found

**Solution:** Train the model
```bash
python main.py --skip-data --skip-cleaning --skip-features
```

### Issue: API key warnings

**Solution:** Add your OpenWeather API key to `.env`
```
OPENWEATHER_API_KEY=your_key_here
```

---

## ğŸ“ License

This project is licensed under the MIT License.

---

## ğŸ‘¥ Contributors

- Transport Analytics Team

---

## ğŸ“§ Support

For issues and questions, please check:
1. `PROJECT_ANALYSIS.md` - Detailed architecture analysis
2. `IMPLEMENTATION_PLAN.md` - Development roadmap

---

## ğŸ“ Academic Use

This project demonstrates:
- Complete ML pipeline (data â†’ model â†’ deployment)
- RESTful API design
- Database design and migrations
- Real-time data integration
- Modern web application development
- Software engineering best practices

Perfect for final year projects, ML portfolios, and learning full-stack ML development!

---

**Built with â¤ï¸ for Hyderabad's commuters**
